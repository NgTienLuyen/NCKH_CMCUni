{"cells":[{"cell_type":"markdown","metadata":{"id":"tACphGuWQ3Do"},"source":["# MÔ HÌNH PHÂN LOẠI ÂM THANH DỰA TRÊN MÔ HÌNH CNN14"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24241,"status":"ok","timestamp":1718839181635,"user":{"displayName":"Tiến Luyện Nguyễn","userId":"14181701096745099528"},"user_tz":-420},"id":"TGbmBojAyJvp","outputId":"14fe8342-583d-4add-c320-3a04d5e4b99c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting paddlepaddle\n","  Downloading paddlepaddle-2.6.1-cp310-cp310-manylinux1_x86_64.whl (125.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from paddlepaddle)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (9.4.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (4.4.2)\n","Collecting astor (from paddlepaddle)\n","  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.3.0)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.20.3)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (2024.6.2)\n","Collecting httpcore==1.* (from httpx->paddlepaddle)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->paddlepaddle) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->paddlepaddle)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->paddlepaddle) (1.2.1)\n","Installing collected packages: h11, astor, httpcore, httpx, paddlepaddle\n","Successfully installed astor-0.8.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 paddlepaddle-2.6.1\n"]}],"source":["!pip install paddlepaddle\n","import os\n","import librosa\n","import numpy as np\n","import cv2\n","import paddle\n","import paddle.nn as nn\n","import paddle.nn.functional as F\n","from paddle.io import Dataset, DataLoader, random_split\n"]},{"cell_type":"markdown","metadata":{"id":"bTC3dlXtQNt8"},"source":["1. Chuẩn hóa theo dải giá trị\n","Đoạn code này giả định rằng sample là một tensor (hoặc mảng numpy) chứa giá trị của một ảnh âm thanh sau khi được xử lý thành hình ảnh (ví dụ: mel spectrogram) và có giá trị nằm trong khoảng từ 0 đến 255 (hoặc bất kỳ dải giá trị nào tương tự).\n","**sample = sample / 255.0**\n","Bước này chia toàn bộ giá trị của sample cho 255.0. Điều này sẽ đưa các giá trị từ dải [0, 255] về dải [0.0, 1.0]. Đây là bước chuẩn hóa đơn giản để đưa dữ liệu về cùng một phạm vi.\n","2. Đưa về trung tâm 0\n","**sample -= 0.5**\n","Bước này trừ đi 0.5 từ mỗi giá trị trong sample. Sau bước này, các giá trị trong sample sẽ nằm trong khoảng [-0.5, 0.5]. Điều này giúp dịch chuyển dữ liệu để tâm tại 0, giúp mô hình dễ dàng học các biến đổi tuyến tính.\n","3. Scale lại để có dải giá trị rộng hơn\n","sample *= 2.0\n","Bước cuối cùng nhân mỗi giá trị trong sample với 2.0. Kết quả là các giá trị trong sample sẽ nằm trong khoảng [-1.0, 1.0]. Điều này làm mở rộng khoảng giá trị của dữ liệu, giúp cho mô hình dễ dàng học hơn và có thể cải thiện độ chính xác của mô hình."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":454,"status":"ok","timestamp":1718839195392,"user":{"displayName":"Tiến Luyện Nguyễn","userId":"14181701096745099528"},"user_tz":-420},"id":"-6UYBAgRyQLK"},"outputs":[],"source":["class Normalize(object):\n","    def __call__(self, sample):\n","        sample = sample / 255.0\n","        sample -= 0.5\n","        sample *= 2.0\n","        return sample\n"]},{"cell_type":"markdown","metadata":{"id":"iR4rhXkMS8bx"},"source":["Lớp AudioDataset dành cho việc xử lý dữ liệu âm thanh. Hãy đi vào từng phương thức và thuộc tính của lớp này để hiểu rõ hơn:\n","1. Phương thức __init__\n","audio_dir: Đường dẫn đến thư mục chứa dữ liệu âm thanh.\n","labels: Danh sách các nhãn (labels) cho các lớp âm thanh (vd: ['Bac', 'Nam', 'Trung']).\n","transform: Hàm biến đổi để xử lý ảnh (nếu có).\n","file_paths: Danh sách các đường dẫn tới các file âm thanh (.wav) trong thư mục audio_dir.\n","targets: Danh sách các chỉ số tương ứng với nhãn của mỗi file âm thanh trong file_paths.\n","Trong phương thức __init__, một lần khởi tạo đối tượng AudioDataset, nó sẽ duyệt qua từng nhãn và từng file âm thanh trong thư mục audio_dir. Nếu file đó là file âm thanh (.wav), nó sẽ thêm đường dẫn của file và chỉ số của nhãn vào file_paths và targets tương ứng.\n","2. Phương thức __len__\n","Phương thức này trả về số lượng mẫu trong dataset, tức là số lượng file âm thanh đã được tải và chuẩn bị trong file_paths.\n","3. Phương thức __getitem__\n","idx: Chỉ số của mẫu trong dataset mà bạn muốn truy cập.\n","Phương thức __getitem__ được gọi khi bạn gọi dataset[idx] để lấy một mẫu từ dataset.\n","\n","file_path: Lấy đường dẫn của file âm thanh tại vị trí idx trong file_paths.\n","target: Lấy nhãn của file âm thanh tại vị trí idx trong targets.\n","Tiếp theo, nó sẽ:\n","\n","Sử dụng librosa để tải âm thanh từ file_path, giới hạn độ dài là 2.5 giây, bắt đầu từ vị trí 0.6 giây.\n","Tính toán Mel spectrogram và chuyển đổi sang đơn vị độ dB (mel_spect_db).\n","Thực hiện resize ảnh đến kích thước 128x128 sử dụng OpenCV (cv2.resize).\n","Mở rộng chiều của ảnh để có một kênh duy nhất (single channel) và chuyển đổi sang kiểu dữ liệu float32.\n","Cuối cùng, nếu transform được cung cấp (thường là một hàm biến đổi), nó sẽ áp dụng transform lên ảnh (vd: chuẩn hóa, augmentation,...).\n","\n","Kết quả trả về là cặp (img, target), trong đó img là đầu vào cho mô hình (ảnh Mel spectrogram đã được xử lý), và target là nhãn tương ứng của mẫu đó.\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1718839199205,"user":{"displayName":"Tiến Luyện Nguyễn","userId":"14181701096745099528"},"user_tz":-420},"id":"R2HjBhcHySsw"},"outputs":[],"source":["class AudioDataset(Dataset):\n","    def __init__(self, audio_dir, labels, transform=None):\n","        self.audio_dir = audio_dir\n","        self.labels = labels\n","        self.transform = transform\n","        self.file_paths = []\n","        self.targets = []\n","\n","        for label in labels:\n","            folder_path = os.path.join(audio_dir, label)\n","            for file_name in os.listdir(folder_path):\n","                if file_name.endswith('.wav'):\n","                    self.file_paths.append(os.path.join(folder_path, file_name))\n","                    self.targets.append(labels.index(label))\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, idx):\n","        file_path = self.file_paths[idx]\n","        target = self.targets[idx]\n","\n","        y, sr = librosa.load(file_path, duration=2.5, offset=0.6)\n","        mel_spect = librosa.feature.melspectrogram(y=y, sr=sr)\n","        mel_spect_db = librosa.power_to_db(mel_spect, ref=np.max)\n","        img = cv2.resize(mel_spect_db, (128, 128))\n","        img = np.expand_dims(img, axis=0).astype(np.float32)  # Convert to single channel\n","\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        return img, target\n"]},{"cell_type":"markdown","metadata":{"id":"GEJvMJ9OarWK"},"source":["1. Định nghĩa nhãn và tải dữ liệu\n","labels: Danh sách các nhãn của dữ liệu âm thanh. Trong trường hợp này, có ba nhãn là 'Bac', 'Nam', và 'Trung'.\n","audio_dir: Đường dẫn tới thư mục chứa dữ liệu âm thanh. Trong ví dụ này, dữ liệu âm thanh được lưu tại '/content/drive/MyDrive/VOICE/dulieu'.\n","dataset: Đối tượng của lớp AudioDataset, được khởi tạo với audio_dir, labels, và một đối tượng biến đổi Normalize() để chuẩn hóa dữ liệu.\n","\n","2. Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n","train_size: Số lượng mẫu trong tập huấn luyện, lấy là 80% của số lượng mẫu trong dataset.\n","test_size: Số lượng mẫu trong tập kiểm tra, bằng phần còn lại của dataset sau khi lấy tập huấn luyện.\n","random_split(dataset, [train_size, test_size]): Hàm random_split từ paddle.io được sử dụng để chia dataset thành hai phần tập huấn luyện (train_dataset) và tập kiểm tra (test_dataset).\n","\n","3. Tạo DataLoader\n","train_loader: DataLoader cho tập huấn luyện, được tạo từ train_dataset, với batch_size là 32 (tức là mỗi lần đọc vào mô hình sẽ được cung cấp 32 mẫu).\n","test_loader: DataLoader cho tập kiểm tra, được tạo từ test_dataset, cũng với batch_size là 32. shuffle=False để đảm bảo dữ liệu kiểm tra không bị xáo trộn.\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5953,"status":"ok","timestamp":1718839209517,"user":{"displayName":"Tiến Luyện Nguyễn","userId":"14181701096745099528"},"user_tz":-420},"id":"XHfi89fbyWKz"},"outputs":[],"source":["# Define Labels and Load Dataset\n","labels = ['Bac', 'Nam', 'Trung']\n","audio_dir = '/content/drive/MyDrive/VOICE/dulieu'\n","dataset = AudioDataset(audio_dir, labels, transform=Normalize())\n","\n","# Split Dataset\n","train_size = int(0.8 * len(dataset))\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"]},{"cell_type":"markdown","metadata":{"id":"qrKc3ndjbDn9"},"source":["Lớp ConvBlock trong đoạn code là một khối convolution được xây dựng để sử dụng trong mô hình của bạn. Hãy đi vào từng thành phần của nó để hiểu cách hoạt động:\n","\n","1. Hàm khởi tạo __init__\n","in_channels: Số kênh đầu vào của dữ liệu.\n","out_channels: Số kênh đầu ra (số lượng filter) của lớp convolution.\n","Trong hàm khởi tạo này:\n","\n","self.conv1 và self.conv2 là hai lớp convolution 2D với kernel size là 3x3, stride là 1 và padding là 1. in_channels là số kênh đầu vào của lớp convolution đầu tiên và out_channels là số kênh đầu ra của cả hai lớp convolution.\n","self.bn1 và self.bn2 là hai lớp Batch Normalization để chuẩn hóa giá trị đầu ra của các lớp convolution trước khi đưa vào hàm kích hoạt (ReLU).\n","\n","2. Phương thức forward:\n","- x: Đầu vào của khối convolution, là một tensor.\n","pool_size: Kích thước cửa sổ pooling.\n","pool_type: Loại pooling được sử dụng ('max', 'avg', 'avg+max').\n","- Trong phương thức forward:\n","\n","+ Đầu tiên, đầu vào x được đi qua lớp convolution đầu tiên (self.conv1), sau đó chuẩn hóa bằng Batch Normalization (self.bn1) và áp dụng hàm kích hoạt ReLU (F.relu).\n","+ Tiếp theo, đầu ra của lớp convolution thứ nhất được đi qua lớp convolution thứ hai (self.conv2), sau đó chuẩn hóa bằng Batch Normalization (self.bn2) và áp dụng hàm kích hoạt ReLU.\n","+ Sau khi hoàn thành các phép tính trên, lựa chọn loại pooling dựa trên tham số pool_type:\n"," + Nếu pool_type là 'max', sử dụng pooling max (F.max_pool2d).\n"," + Nếu pool_type là 'avg', sử dụng pooling average (F.avg_pool2d).\n"," + Nếu pool_type là 'avg+max', thực hiện cả hai loại pooling và cộng kết quả lại với nhau.\n"," + Nếu không phù hợp với bất kỳ loại nào trong các loại trên, raise một ngoại lệ (Exception).\n","+ Kết quả của phương thức forward là đầu ra của khối convolution sau khi áp dụng các lớp convolution, Batch Normalization và pooling tương ứng. Đây là một khối cơ bản được sử dụng để xây dựng mô hình CNN trong bài toán phân loại âm thanh của bạn.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":612,"status":"ok","timestamp":1718839213783,"user":{"displayName":"Tiến Luyện Nguyễn","userId":"14181701096745099528"},"user_tz":-420},"id":"TXYc93dEyZuy"},"outputs":[],"source":["class ConvBlock(nn.Layer):\n","    def __init__(self, in_channels, out_channels):\n","        super(ConvBlock, self).__init__()\n","        self.conv1 = nn.Conv2D(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2D(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2D(out_channels)\n","        self.bn2 = nn.BatchNorm2D(out_channels)\n","\n","    def forward(self, x, pool_size=(2, 2), pool_type='avg'):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        if pool_type == 'max':\n","            x = F.max_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg':\n","            x = F.avg_pool2d(x, kernel_size=pool_size)\n","        elif pool_type == 'avg+max':\n","            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n","            x2 = F.max_pool2d(x, kernel_size=pool_size)\n","            x = x1 + x2\n","        else:\n","            raise Exception('Incorrect argument!')\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"wuo9VK0teYNf"},"source":["Lớp Cnn14 là một mô hình mạng nơ-ron tích chập (CNN) được thiết kế để phân loại âm thanh vào ba lớp (\"Bac\", \"Nam\", \"Trung\"). Hãy đi vào từng thành phần của lớp này để hiểu cách hoạt động:\n","1. Hàm khởi tạo __init__:\n","- self.bn0: Lớp Batch Normalization cho đầu vào đầu tiên, có 1 kênh.\n","- self.conv_block1 đến self.conv_block6: Sáu khối convolution, mỗi khối được xây dựng từ lớp ConvBlock. Các khối này có số kênh đầu vào và đầu ra tăng dần để học các đặc trưng phức tạp hơn khi đi sâu vào mạng.\n","- self.fc1: Lớp fully connected (dense) với đầu vào 2048 và đầu ra 2048.\n","- self.fc_audioset: Lớp fully connected cuối cùng với đầu vào 2048 và đầu ra 3, tương ứng với số lớp đầu ra (Ba, Nam, Trung).\n","\n","2. Phương thức forward:\n","- x: Đầu vào của mô hình, là một tensor.\n","- self.bn0(x): Chuẩn hóa đầu vào đầu tiên bằng Batch Normalization.\n","- self.conv_block1 đến self.conv_block6: Các khối convolution tuần tự, mỗi khối là một đối tượng của lớp ConvBlock được gọi với tham số pool_size=(2, 2) và pool_type='avg'. Đây là các khối tích chập liên tiếp nhau để học các đặc trưng từ dữ liệu.\n","- F.dropout(x, p=0.2, training=self.training): Áp dụng dropout để ngăn chặn overfitting trong quá trình huấn luyện. p=0.2 là tỷ lệ dropout (20%).\n","- x.mean(axis=3, keepdim=True): Lấy giá trị trung bình theo chiều thứ 3 của x.\n","- x1 = x.max(axis=2, keepdim=True): Lấy giá trị lớn nhất theo chiều thứ 2 của x.\n","- x2 = x1.mean(axis=2, keepdim=True): Lấy giá trị trung bình theo chiều thứ 2 của x1.\n","- x = x1 + x2: Cộng hai tensor x1 và x2.\n","- x.squeeze(): Loại bỏ các chiều có kích thước là 1.\n","- F.dropout(x, p=0.5, training=self.training): Áp dụng dropout với tỷ lệ 50% trước khi đi qua lớp fully connected đầu tiên (self.fc1).\n","- F.relu(self.fc1(x)): Áp dụng hàm kích hoạt ReLU cho đầu ra của lớp fully connected đầu tiên."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":549,"status":"ok","timestamp":1718839219469,"user":{"displayName":"Tiến Luyện Nguyễn","userId":"14181701096745099528"},"user_tz":-420},"id":"F9H1dGorycpD"},"outputs":[],"source":["class Cnn14(nn.Layer):\n","    def __init__(self):\n","        super(Cnn14, self).__init__()\n","        self.bn0 = nn.BatchNorm2D(1)\n","        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n","        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n","        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n","        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n","        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n","        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n","        self.fc1 = nn.Linear(2048, 2048)\n","        self.fc_audioset = nn.Linear(2048, 3)\n","\n","    def forward(self, x):\n","        x = self.bn0(x)\n","        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n","        x = F.dropout(x, p=0.2, training=self.training)\n","        x = x.mean(axis=3, keepdim=True)\n","        x1 = x.max(axis=2, keepdim=True)\n","        x2 = x1.mean(axis=2, keepdim=True)\n","        x = x1 + x2\n","        x = x.squeeze()\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.relu(self.fc1(x))\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"eEw_sT9VfLTr"},"source":["Lớp ESCModel là một mô hình tổng hợp dựa trên mô hình CNN Cnn14 để phân loại âm thanh vào ba lớp (\"Bac\", \"Nam\", \"Trung\").\n","1. Hàm khởi tạo __init__\n","- self.audioset_model: Lớp Cnn14 được khởi tạo làm thành phần của mô hình. Đây là mô hình CNN để trích xuất đặc trưng từ dữ liệu âm thanh.\n","- self.fc_esc50: Lớp fully connected cuối cùng với đầu vào 2048 (đầu ra của Cnn14) và đầu ra 3, tương ứng với số lớp đầu ra (\"Bac\", \"Nam\", \"Trung\").\n","\n","2. Phương thức forward\n","- x: Đầu vào của mô hình, là một tensor.\n","self.audioset_model(x): Đưa đầu vào x qua mô hình Cnn14 để trích xuất đặc trưng.\n","- F.dropout(out, p=0.5, training=self.training): Áp dụng dropout với tỷ lệ 50% cho đầu ra của Cnn14, nhằm ngăn chặn overfitting trong quá trình huấn luyện.\n","- self.fc_esc50(out): Đưa đầu ra của dropout qua lớp fully connected cuối cùng để tính toán logits (điểm số) cho các lớp đầu ra."]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1718839226715,"user":{"displayName":"Tiến Luyện Nguyễn","userId":"14181701096745099528"},"user_tz":-420},"id":"iitVzwc1yfWZ"},"outputs":[],"source":["class ESCModel(paddle.nn.Layer):\n","    def __init__(self):\n","        super(ESCModel, self).__init__()\n","        self.audioset_model = Cnn14()\n","        self.fc_esc50 = paddle.nn.Linear(2048, 3)\n","\n","    def forward(self, x):\n","        out = self.audioset_model(x)\n","        out = F.dropout(out, p=0.5, training=self.training)\n","        logits = self.fc_esc50(out)\n","        return logits\n"]},{"cell_type":"markdown","metadata":{"id":"mf7bet9if7OI"},"source":["QUÁ TRÌNH HUẤN LUYỆN:\n","1. Khởi tạo mô hình và các thành phần cần thiết\n","- Khởi tạo một đối tượng ESCModel, mô hình sẽ được sử dụng để huấn luyện và dự đoán.\n","\n","2. Định nghĩa hàm loss và optimizer\n","- CrossEntropyLoss: Hàm mất mát dùng để tính toán sự mất mát giữa các dự đoán và nhãn.\n","- Adam: Trình tối ưu hóa Adam được sử dụng để cập nhật các tham số của mô hình dựa trên gradient của hàm mất mát.\n","\n","3. Huấn luyện mô hình\n","- Vòng lặp for epoch in range(epochs) chạy qua số lượng epochs đã chỉ định.\n","- model.train(): Thiết lập mô hình ở chế độ huấn luyện.\n","- train_loader: Dataloader chứa dữ liệu huấn luyện.\n","- Vòng lặp bên trong lặp qua train_loader để lấy dữ liệu đầu vào (inputs) và nhãn (labels).\n","- outputs = model(inputs): Dự đoán đầu ra của mô hình.\n","- loss = criterion(outputs, labels): Tính toán hàm mất mát giữa dự đoán và nhãn.\n","- loss.backward(): Lan truyền ngược để tính gradient của các tham số.\n","-optimizer.step(): Cập nhật các tham số của mô hình bằng cách sử dụng optimizer.\n","- optimizer.clear_grad(): Xóa gradient sau mỗi lần cập nhật tham số để chuẩn bị cho lần cập nhật tiếp theo.\n","- running_loss += loss.item(): Cộng dồn hàm mất mát để tính tổng hàm mất mát trung bình sau mỗi epoch.\n","- print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}'): In ra giá trị trung bình của hàm mất mát trong quá trình huấn luyện.\n","\n","4. Đánh giá mô hình\n","5. Lưu mô hình"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUjSBtNryhuJ","executionInfo":{"status":"ok","timestamp":1718846467202,"user_tz":-420,"elapsed":3103842,"user":{"displayName":"Tiến Luyện Nguyễn","userId":"14181701096745099528"}},"outputId":"2f500928-e14c-4939-9eac-99de8ec3cca0"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/paddle/nn/layer/norm.py:824: UserWarning: When training, we now always track global mean and variance.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 3.272491453862232\n","Validation Accuracy: 89.85507246376811%\n","Epoch 2/10, Loss: 1.5790609271886449\n","Validation Accuracy: 89.85507246376811%\n","Epoch 3/10, Loss: 0.9462968382156558\n","Validation Accuracy: 88.40579710144928%\n","Epoch 4/10, Loss: 0.6088133835130267\n","Validation Accuracy: 89.85507246376811%\n","Epoch 5/10, Loss: 0.8691312821562557\n","Validation Accuracy: 89.85507246376811%\n","Epoch 6/10, Loss: 0.6693166063891517\n","Validation Accuracy: 89.85507246376811%\n","Epoch 7/10, Loss: 1.6971213484389915\n","Validation Accuracy: 89.85507246376811%\n","Epoch 8/10, Loss: 0.5539501698480712\n","Validation Accuracy: 89.85507246376811%\n","Epoch 9/10, Loss: 0.5426625675625272\n","Validation Accuracy: 86.23188405797102%\n","Epoch 10/10, Loss: 0.746419271454215\n","Validation Accuracy: 89.85507246376811%\n"]}],"source":["model = ESCModel()\n","\n","criterion = paddle.nn.CrossEntropyLoss()\n","optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=0.001)\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.clear_grad()\n","        running_loss += loss.item()\n","    print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}')\n","\n","    # Validation loop\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with paddle.no_grad():\n","        for inputs, labels in test_loader:\n","            outputs = model(inputs)\n","            _, predicted = paddle.topk(outputs, k=1)\n","            total += labels.shape[0]\n","            correct += (predicted.squeeze() == labels).sum().item()\n","\n","    print(f'Validation Accuracy: {100 * correct / total}%')\n","\n","# Save model\n","paddle.save(model.state_dict(), 'model.pdparams')\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1YsrjfsQnWrc35-JVepgoe8uVyFgOvAyD","authorship_tag":"ABX9TyNgaB0o5aEfjz6+mpDo3HaX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}